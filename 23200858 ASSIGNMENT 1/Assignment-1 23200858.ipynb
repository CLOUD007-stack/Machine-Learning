{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374e71bc",
   "metadata": {},
   "source": [
    "## Assignment 1 - The Bean Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bc6acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272751</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0  28395    610.291       208.178117       173.888747      1.197191   \n",
       "1  28734    638.018       200.524796       182.734419      1.097356   \n",
       "2  29380    624.110       212.826130       175.931143      1.209713   \n",
       "3  30008    645.884       210.557999       182.516516      1.153638   \n",
       "4  30140    620.134       201.847882       190.279279      1.060798   \n",
       "\n",
       "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1      0.411785       29172     191.272751  0.783968  0.984986   0.887034   \n",
       "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "\n",
       "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
       "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
       "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
       "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
       "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
       "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Loading dataset \n",
    "data = pd.read_csv('Dry_Bean_Dataset.csv')\n",
    "\n",
    "# Head dataset \n",
    "data.head()\n",
    "\n",
    "# data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea143d",
   "metadata": {},
   "source": [
    "# Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5576d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finding Missing values\n",
    "# missing_values = data.isnull().sum()\n",
    "\n",
    "# # Drop missing rows values\n",
    "# data = data.dropna()\n",
    "\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caaa1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satndard Scaler  \n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64615a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here taking Training 80%, Testing 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab4bd7",
   "metadata": {},
   "source": [
    "## Implementation classification models:\n",
    "####  Accuracy, Precision, Recall and Confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13081d22",
   "metadata": {},
   "source": [
    "### 1. KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2d61ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------K-Nearest Neighbour--------\n",
      "\n",
      "Accuracy = 92.9122291590158\n",
      "Precision = 92.92990003609243\n",
      "Recall = 92.9122291590158\n",
      "\n",
      "-----------------------------------\n",
      "Confusion Matrix:\n",
      "\n",
      "[[243   0  16   0   0   1   3]\n",
      " [  0  99   0   0   0   0   0]\n",
      " [  7   0 282   0   5   1   2]\n",
      " [  0   0   0 649   1   8  47]\n",
      " [  0   0   9   1 391   0   7]\n",
      " [  1   0   0   7   1 390   8]\n",
      " [  1   0   0  50   8   9 476]]\n",
      "\n",
      "--------------------------------\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.96      0.92      0.94       263\n",
      "      BOMBAY       1.00      1.00      1.00        99\n",
      "        CALI       0.92      0.95      0.93       297\n",
      "    DERMASON       0.92      0.92      0.92       705\n",
      "       HOROZ       0.96      0.96      0.96       408\n",
      "       SEKER       0.95      0.96      0.96       407\n",
      "        SIRA       0.88      0.88      0.88       544\n",
      "\n",
      "    accuracy                           0.93      2723\n",
      "   macro avg       0.94      0.94      0.94      2723\n",
      "weighted avg       0.93      0.93      0.93      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# K-Nearest Neighbour\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "knn_precision = precision_score(y_test, knn_pred, average='weighted')\n",
    "knn_recall = recall_score(y_test, knn_pred, average='weighted')\n",
    "knn_confusion_matrix = confusion_matrix(y_test, knn_pred)\n",
    "\n",
    "# Results\n",
    "print(\"--------K-Nearest Neighbour--------\")\n",
    "print(\"\\nAccuracy =\", knn_accuracy*100)\n",
    "print(\"Precision =\", knn_precision*100)\n",
    "print(\"Recall =\", knn_recall*100)\n",
    "print(\"\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(knn_confusion_matrix)\n",
    "print(\"\\n--------------------------------\")\n",
    "print(\"Classification Report:\\n\")\n",
    "reportknn = classification_report(y_test, knn_pred)\n",
    "print(reportknn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c605c",
   "metadata": {},
   "source": [
    "### 2. DecisionTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48969ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Decision Tree---------\n",
      "\n",
      "Accuracy = 89.46015424164524\n",
      "Precision = 91.02835660836588\n",
      "Recall = 91.13636244319144\n",
      "\n",
      "--------------------------------\n",
      "Confusion Matrix:\n",
      "[[240   0  14   0   0   5   4]\n",
      " [  0  99   0   0   0   0   0]\n",
      " [ 21   0 268   0   6   1   1]\n",
      " [  0   0   0 625   9   7  64]\n",
      " [  2   0   7   4 380   0  15]\n",
      " [  7   0   1  15   0 375   9]\n",
      " [  6   0   2  64   9  14 449]]\n",
      "\n",
      "--------------------------------\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.87      0.91      0.89       263\n",
      "      BOMBAY       1.00      1.00      1.00        99\n",
      "        CALI       0.92      0.90      0.91       297\n",
      "    DERMASON       0.88      0.89      0.88       705\n",
      "       HOROZ       0.94      0.93      0.94       408\n",
      "       SEKER       0.93      0.92      0.93       407\n",
      "        SIRA       0.83      0.83      0.83       544\n",
      "\n",
      "    accuracy                           0.89      2723\n",
      "   macro avg       0.91      0.91      0.91      2723\n",
      "weighted avg       0.89      0.89      0.89      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=30)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "dt_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "dt_precision = precision_score(y_test, dt_pred, average='macro')\n",
    "dt_recall = recall_score(y_test, dt_pred, average='macro')\n",
    "dt_confusion_matrix = confusion_matrix(y_test, dt_pred)\n",
    "\n",
    "# Results\n",
    "print(\"----------Decision Tree---------\")\n",
    "print(\"\\nAccuracy =\", dt_accuracy*100)\n",
    "print(\"Precision =\", dt_precision*100)\n",
    "print(\"Recall =\", dt_recall*100)\n",
    "print(\"\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(dt_confusion_matrix)\n",
    "print(\"\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Classification Report:\\n\")\n",
    "reportdt = classification_report(y_test, dt_pred)\n",
    "print(reportdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8184fc8",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83afcde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Logistic Regression---------\n",
      "\n",
      "Accuracy = 92.06757253029747\n",
      "Precision = 92.1885282156184\n",
      "Recall = 92.06757253029747\n",
      "\n",
      "--------------------------------------\n",
      "Confusion Matrix:\n",
      "[[237   0  14   0   0   2  10]\n",
      " [  0  99   0   0   0   0   0]\n",
      " [  6   0 272   0  10   1   8]\n",
      " [  1   0   0 640   3  10  51]\n",
      " [  2   0   5   2 389   0  10]\n",
      " [  3   0   0   3   1 386  14]\n",
      " [  0   0   1  47   7   5 484]]\n",
      "\n",
      "--------------------------------\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.90      0.93       263\n",
      "      BOMBAY       1.00      1.00      1.00        99\n",
      "        CALI       0.93      0.92      0.92       297\n",
      "    DERMASON       0.92      0.91      0.92       705\n",
      "       HOROZ       0.95      0.95      0.95       408\n",
      "       SEKER       0.96      0.95      0.95       407\n",
      "        SIRA       0.84      0.89      0.86       544\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.94      0.93      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "lr_pred = logistic_reg.predict(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "lr_precision = precision_score(y_test, lr_pred, average='weighted')\n",
    "lr_recall = recall_score(y_test, lr_pred, average='weighted')\n",
    "lr_confusion_matrix = confusion_matrix(y_test, lr_pred)\n",
    "\n",
    "# Results\n",
    "print(\"----------Logistic Regression---------\\n\")\n",
    "print(\"Accuracy =\", lr_accuracy*100)\n",
    "print(\"Precision =\", lr_precision*100)\n",
    "print(\"Recall =\", lr_recall*100)\n",
    "print(\"\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(lr_confusion_matrix)\n",
    "print(\"\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Classification Report:\\n\")\n",
    "reportlr = classification_report(y_test, lr_pred)\n",
    "print(reportlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087840c9",
   "metadata": {},
   "source": [
    "### 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5001e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Random Forest-------------\n",
      "Accuracy = 93.68343738523687\n",
      "Precision = 93.67568656898777\n",
      "Recall = 93.68343738523687\n",
      "\n",
      "--------------------------------------\n",
      "Confusion Matrix:\n",
      "[[246   0  12   0   0   2   3]\n",
      " [  0  99   0   0   0   0   0]\n",
      " [ 11   0 277   0   6   1   2]\n",
      " [  0   0   0 667   2   6  30]\n",
      " [  1   0   6   2 393   0   6]\n",
      " [  1   0   0   8   0 394   4]\n",
      " [  0   0   1  50   8  10 475]]\n",
      "\n",
      "--------------------------------\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.94      0.94       263\n",
      "      BOMBAY       1.00      1.00      1.00        99\n",
      "        CALI       0.94      0.93      0.93       297\n",
      "    DERMASON       0.92      0.95      0.93       705\n",
      "       HOROZ       0.96      0.96      0.96       408\n",
      "       SEKER       0.95      0.97      0.96       407\n",
      "        SIRA       0.91      0.87      0.89       544\n",
      "\n",
      "    accuracy                           0.94      2723\n",
      "   macro avg       0.95      0.95      0.95      2723\n",
      "weighted avg       0.94      0.94      0.94      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=30)\n",
    "random_forest.fit(X_train, y_train)\n",
    "rf_pred = random_forest.predict(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_precision = precision_score(y_test, rf_pred, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_pred, average='weighted')\n",
    "rf_confusion_matrix = confusion_matrix(y_test, rf_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"------------Random Forest-------------\")\n",
    "print(\"Accuracy =\", rf_accuracy*100)\n",
    "print(\"Precision =\", rf_precision*100)\n",
    "print(\"Recall =\", rf_recall*100)\n",
    "print(\"\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(rf_confusion_matrix)\n",
    "print(\"\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"Classification Report:\\n\")\n",
    "reportrf = classification_report(y_test, rf_pred)\n",
    "print(reportrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e58b6",
   "metadata": {},
   "source": [
    "###\n",
    " In this above case, the Random Forest Model has the highest scores for Accuracy, Precision, and Recall. \n",
    " 1. Accuracy - measuring how accurately predictions are made overall.\n",
    " 2. Precision - measurement for how well a model can predict the future.\n",
    " 3. Recall - measures how well a model can find all instances of success. \n",
    " \n",
    "\n",
    "In this first task we have calculated the accuracy which is based on the confusion matrix which gives us the outcome of the results. \n",
    " \n",
    "Overall, all of the models have decent predictive potential, but in this case, Random Forest perform best.\n",
    " \n",
    "In the above scenario we seen that all models shows their values, all models exhibited accuracy rates more than approximately 89%, which is a respectable outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979e07f",
   "metadata": {},
   "source": [
    "# Task 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410494e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DERMASON    3546\n",
      "SIRA        2636\n",
      "SEKER       2027\n",
      "HOROZ       1928\n",
      "CALI        1630\n",
      "BARBUNYA    1322\n",
      "BOMBAY       522\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = data['Class'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193851ae",
   "metadata": {},
   "source": [
    "### Method 1 : Using SMOTE for Descision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896c795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Decision Tree Accuracy with changing the class weights:\n",
      "\n",
      "Accuracy:  91.36981270657363 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.92      0.92      0.92       263\n",
      "      BOMBAY       1.00      1.00      1.00        99\n",
      "        CALI       0.92      0.91      0.92       297\n",
      "    DERMASON       0.93      0.88      0.90       705\n",
      "       HOROZ       0.94      0.96      0.95       408\n",
      "       SEKER       0.93      0.94      0.93       407\n",
      "        SIRA       0.84      0.89      0.87       544\n",
      "\n",
      "    accuracy                           0.91      2723\n",
      "   macro avg       0.93      0.93      0.93      2723\n",
      "weighted avg       0.91      0.91      0.91      2723\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Before Descision Tree Results:\n",
      "Accuracy :  89.46015424164524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.87      0.91      0.89       263\n",
      "      BOMBAY       1.00      1.00      1.00        99\n",
      "        CALI       0.92      0.90      0.91       297\n",
      "    DERMASON       0.88      0.89      0.88       705\n",
      "       HOROZ       0.94      0.93      0.94       408\n",
      "       SEKER       0.93      0.92      0.93       407\n",
      "        SIRA       0.83      0.83      0.83       544\n",
      "\n",
      "    accuracy                           0.89      2723\n",
      "   macro avg       0.91      0.91      0.91      2723\n",
      "weighted avg       0.89      0.89      0.89      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Here we taking 80% for traning and 20% for Testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=30)\n",
    "\n",
    "class_weights = {'SIRA':10, 'BARBUNYA':1, 'BOMBAY':1, 'CALI':1, 'DERMASON':1, 'HOROZ':1, 'SEKER':1}\n",
    "dt = DecisionTreeClassifier(class_weight=class_weights,max_depth=25,random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "dt.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = dt.predict(X_test)\n",
    "smdtacc=accuracy_score(y_test, y_pred)\n",
    "print('SMOTE Decision Tree Accuracy with changing the class weights:\\n')\n",
    "\n",
    "print(\"Accuracy: \",smdtacc*100,\"\\n\")\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(classification_rep)\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print(\"\\nBefore Descision Tree Results:\")\n",
    "print(\"Accuracy : \",dt_accuracy*100)\n",
    "print(reportdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aef7cd",
   "metadata": {},
   "source": [
    "### Method 2 : Using GRID(Hyperparameter Tuning) and SMOTE for Descision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fde36fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.47153874403232\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.91      0.93      0.92       263\n",
      "      BOMBAY       1.00      1.00      1.00        99\n",
      "        CALI       0.91      0.93      0.92       297\n",
      "    DERMASON       0.92      0.92      0.92       705\n",
      "       HOROZ       0.96      0.94      0.95       408\n",
      "       SEKER       0.96      0.95      0.95       407\n",
      "        SIRA       0.88      0.88      0.88       544\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.93      0.94      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Before Descision Tree Results:\n",
      "Accuracy :  89.46015424164524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.87      0.91      0.89       263\n",
      "      BOMBAY       1.00      1.00      1.00        99\n",
      "        CALI       0.92      0.90      0.91       297\n",
      "    DERMASON       0.88      0.89      0.88       705\n",
      "       HOROZ       0.94      0.93      0.94       408\n",
      "       SEKER       0.93      0.92      0.93       407\n",
      "        SIRA       0.83      0.83      0.83       544\n",
      "\n",
      "    accuracy                           0.89      2723\n",
      "   macro avg       0.91      0.91      0.91      2723\n",
      "weighted avg       0.89      0.89      0.89      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='f1_weighted', n_jobs=-1)\n",
    "\n",
    "smote = SMOTE(random_state=25)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy*100)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print(\"\\nBefore Descision Tree Results:\")\n",
    "print(\"Accuracy : \",dt_accuracy*100)\n",
    "print(reportdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9a150a",
   "metadata": {},
   "source": [
    "###\n",
    "The above report summarizes the performance of a machine learning model on different classes.\n",
    "\n",
    "1. Precision:-  \n",
    "    1. Measure of the model's ability to make precise predictions\n",
    "    2. How many instances predict certain class are actually the classes in dataset. \n",
    "    3. Calculated for each class indivisually.\n",
    "    4. Above Model provides time about 91% correctness. \n",
    " \n",
    "2. Recall:-\n",
    "    1. Sensitivity or true positive rate \n",
    "    2. Measures the model's ability to identify all positive instances \n",
    "    3. Calculated for each class indivisually.\n",
    "    4. Above Model provides about 90% actaul instance.\n",
    "\n",
    "3. F1-Score:- \n",
    "    1. Harmonic mean of precision and recall\n",
    "    2. It's a single value that balances both precision and recall\n",
    "    3. Calculated for each class indivisually.\n",
    "    4. Above Model indicating a balance between precision and recall\n",
    "    \n",
    "4. Support:- \n",
    "    1. Number of instances for each class in the test dataset\n",
    "    \n",
    "5. Accuracy:- \n",
    "    1. The overall accuracy of the model across all classes. \n",
    "    2. Above Model indicating accuracy is 91%\n",
    "    \n",
    "6. Macro Avg:-\n",
    "    1. The macro average takes the average of precision, recall, and F1-score for all classes without considering class imbalance. \n",
    "    2. Here macro average is 93%.\n",
    "    \n",
    "7. Weighted Avg:-\n",
    "    1. The weighted average takes the average of precision, recall, and F1-score for all classes, considering class imbalance.\n",
    "    2. Here Weighted Avg is 91%.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Method 1: \n",
    "Here we seen that In order to handle class imbalance, the Decision Tree moddel with SMOTE performs better than the model without SMOTE, obtaining better overall F1-scores and a higher accuracy (91.36% vs. 89.46%). SMOTE improves the model's classification accuracy while helping in balancing class performance.\n",
    "When SIRA class not affect the other if it is posinous.\n",
    "\n",
    "\n",
    "Method 2: \n",
    "Using SMOTE and HYPERPARAMETER TUNING on DT, it improves the performance of the model with higher accuracy and F1 score. Which is used to handle the imbalanced data over here. We can see through the previous results of DT and after appliying this method on DT model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
